// Groq Deep Integration - Advanced AI Service Manager
// Features: Spell checking, Deep keyword extraction, Content analysis

export interface TranscriptionResult {
    text: string
    segments: Array<{
        start: number
        end: number
        text: string
    }>
}

export interface SpellCheckResult {
    original: string
    corrected: string
    changes: Array<{ word: string; correction: string; position: number }>
    confidence: number
}

export interface KeywordResult {
    topics: string[]              // Main topics
    viral_keywords: string[]      // Trending/viral words
    seo_keywords: string[]        // SEO-friendly keywords
    highlight_words: string[]     // Words to highlight in subtitles
    suggested_hashtags: string[]  // Recommended hashtags
    content_category: string      // vlog, tutorial, review, etc.
    target_audience: string       // general, youth, family
    emotion_tone: string          // energetic, calm, informative
}

export interface DeepAnalysisResult {
    structure: {
        intro?: { start: number; end: number }
        main_content: Array<{ start: number; end: number; topic: string }>
        outro?: { start: number; end: number }
    }
    pacing: {
        slow_parts: Array<{ start: number; end: number; reason: string }>
        fast_parts: Array<{ start: number; end: number; reason: string }>
        optimal_cuts: Array<{ start: number; end: number; type: string; reason: string }>
    }
    engagement: {
        hook_quality: number  // 0-100
        retention_points: Array<{ time: number; score: number; reason: string }>
        drop_off_risks: Array<{ time: number; risk_level: string; suggestion: string }>
    }
    visual_suggestions: Array<{ time: number; suggestion: string; priority: string }>
    audio_suggestions: Array<{ start: number; end: number; type: string; intensity: string }>
}

export interface AnalysisResult {
    summary: string
    highlights: Array<{
        start: number
        end: number
        reason: string
    }>
    jumpCuts: Array<{
        start: number
        end: number
        reason: string
    }>
    keywords?: string[]
    visual_style?: {
        color_grading?: string
        apply_blur?: boolean
        pacing?: string
    }
    subtitle_settings?: {
        position?: string
        highlight_color?: string
    }
}

export class AIServiceManager {
    private groqKey: string | undefined
    private geminiKey: string | undefined

    constructor() {
        this.groqKey = process.env.GROQ_API_KEY
        this.geminiKey = process.env.GOOGLE_AI_API_KEY
    }

    getAvailableServices(): string[] {
        const services: string[] = []
        if (this.groqKey) services.push('groq')
        if (this.geminiKey) services.push('gemini')
        return services
    }


    // Main transcription with Groq/Gemini fallback
    async transcribe(videoBlob: Blob): Promise<TranscriptionResult> {
        const errors: string[] = []

        // Try Groq Whisper first (primary)
        if (this.groqKey) {
            try {
                console.log('üöÄ Transcribing with Groq Whisper Large v3...')
                return await this.transcribeWithGroq(videoBlob)
            } catch (error: any) {
                const msg = error?.message || String(error)
                console.error('‚ùå Groq failed:', msg)
                errors.push(`Groq: ${msg}`)
            }
        }

        // Fallback to Gemini
        if (this.geminiKey) {
            try {
                console.log('ü§ñ Falling back to Gemini...')
                return await this.transcribeWithGemini(videoBlob)
            } catch (error: any) {
                const msg = error?.message || String(error)
                console.error('‚ùå Gemini failed:', msg)
                errors.push(`Gemini: ${msg}`)
            }
        }

        console.log('‚ö†Ô∏è All AI services failed, using mock data')
        return this.mockTranscription()
    }


    // NEW: Spell checking and correction
    async checkAndCorrectSpelling(text: string): Promise<SpellCheckResult> {
        if (!this.groqKey) {
            console.log('‚ö†Ô∏è No Groq key, skipping spell check')
            return {
                original: text,
                corrected: text,
                changes: [],
                confidence: 0
            }
        }

        try {
            console.log('üìù Running spell check with Groq...')
            const Groq = require('groq-sdk').default
            const groq = new Groq({ apiKey: this.groqKey })

            const prompt = `‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ô‡∏µ‡πâ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ):

"${text}"

‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ JSON:
{
  "corrected": "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÅ‡∏•‡πâ‡∏ß",
  "changes": [
    {"word": "‡∏Ñ‡∏≥‡πÄ‡∏î‡∏¥‡∏°", "correction": "‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å", "position": 0}
  ],
  "confidence": 0.95
}

‡∏Å‡∏é:
- ‡πÅ‡∏Å‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏à‡∏£‡∏¥‡∏á‡πÜ
- ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏î‡∏¥‡∏°
- confidence 0-1 (1 = ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ ‡πÉ‡∏´‡πâ changes ‡πÄ‡∏õ‡πá‡∏ô []`

            const completion = await groq.chat.completions.create({
                model: 'llama-3.3-70b-versatile',
                messages: [{ role: 'user', content: prompt }],
                temperature: 0.3, // Low temp for accuracy
                max_tokens: 2000
            })

            const response = completion.choices[0]?.message?.content
            if (!response) throw new Error('Empty response')

            const match = response.match(/\{[\s\S]*\}/)
            if (!match) throw new Error('No JSON in response')

            const parsed = JSON.parse(match[0])

            console.log(`‚úÖ Spell check: ${parsed.changes.length} corrections, confidence ${parsed.confidence}`)

            return {
                original: text,
                corrected: parsed.corrected || text,
                changes: parsed.changes || [],
                confidence: parsed.confidence || 0
            }
        } catch (error) {
            console.error('Spell check failed:', error)
            return {
                original: text,
                corrected: text,
                changes: [],
                confidence: 0
            }
        }
    }

    // NEW: Advanced keyword extraction
    async extractKeywords(text: string): Promise<KeywordResult> {
        if (!this.groqKey) {
            return this.mockKeywords()
        }

        try {
            console.log('üîë Extracting keywords with Groq...')
            const Groq = require('groq-sdk').default
            const groq = new Groq({ apiKey: this.groqKey })

            const prompt = `‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡∏™‡∏Å‡∏±‡∏î‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:

"${text.substring(0, 1000)}..."

‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ JSON:
{
  "topics": ["‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å1", "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å2"],
  "viral_keywords": ["‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Æ‡∏¥‡∏ï", "‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå"],
  "seo_keywords": ["SEO1", "SEO2"],
  "highlight_words": ["‡∏Ñ‡∏≥‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô1", "‡∏Ñ‡∏≥‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô2"],
  "suggested_hashtags": ["#tag1", "#tag2"],
  "content_category": "vlog",
  "target_audience": "general",
  "emotion_tone": "energetic"
}

‡πÄ‡∏Å‡∏ì‡∏ë‡πå:
- topics: ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å 2-3 ‡∏Ñ‡∏≥
- viral_keywords: ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Æ‡∏¥‡∏ï trendy
- seo_keywords: ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
- highlight_words: ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏ô‡πâ‡∏ô‡πÉ‡∏ô‡∏ã‡∏±‡∏ö (impact words)
- hashtags: 3-5 tags
- category: vlog|tutorial|review|entertainment|travel|food
- audience: general|youth|family|professional
- tone: energetic|calm|informative|funny|serious`

            const completion = await groq.chat.completions.create({
                model: 'llama-3.3-70b-versatile',
                messages: [{ role: 'user', content: prompt }],
                temperature: 0.7,
                max_tokens: 1000
            })

            const response = completion.choices[0]?.message?.content
            if (!response) throw new Error('Empty response')

            const match = response.match(/\{[\s\S]*\}/)
            if (!match) throw new Error('No JSON')

            const parsed = JSON.parse(match[0])

            console.log(`‚úÖ Keywords: ${parsed.topics?.length || 0} topics, ${parsed.viral_keywords?.length || 0} viral`)

            return {
                topics: parsed.topics || [],
                viral_keywords: parsed.viral_keywords || [],
                seo_keywords: parsed.seo_keywords || [],
                highlight_words: parsed.highlight_words || [],
                suggested_hashtags: parsed.suggested_hashtags || [],
                content_category: parsed.content_category || 'general',
                target_audience: parsed.target_audience || 'general',
                emotion_tone: parsed.emotion_tone || 'neutral'
            }
        } catch (error) {
            console.error('Keyword extraction failed:', error)
            return this.mockKeywords()
        }
    }

    // NEW: Deep content analysis
    async deepAnalyze(transcript: TranscriptionResult): Promise<DeepAnalysisResult | null> {
        if (!this.groqKey) return null

        try {
            console.log('üß† Running deep analysis with Groq...')
            const Groq = require('groq-sdk').default
            const groq = new Groq({ apiKey: this.groqKey })

            const text = transcript.text
            const duration = transcript.segments[transcript.segments.length - 1]?.end || 60

            const prompt = `‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:

‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: ${duration}s
Transcript: "${text.substring(0, 1500)}..."

‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ JSON:
{
  "structure": {
    "intro": {"start": 0, "end": 10},
    "main_content": [{"start": 10, "end": 90, "topic": "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠"}],
    "outro": {"start": 90, "end": 100}
  },
  "pacing": {
    "slow_parts": [{"start": 20, "end": 30, "reason": "‡∏û‡∏π‡∏î‡∏ä‡πâ‡∏≤"}],
    "fast_parts": [{"start": 50, "end": 60, "reason": "‡∏û‡∏π‡∏î‡πÄ‡∏£‡πá‡∏ß"}],
    "optimal_cuts": [{"start": 5, "end": 7, "type": "silence", "reason": "‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏ô‡∏≤‡∏ô"}]
  },
  "engagement": {
    "hook_quality": 85,
    "retention_points": [{"time": 15, "score": 90, "reason": "‡∏à‡∏∏‡∏î‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à"}],
    "drop_off_risks": [{"time": 40, "risk_level": "medium", "suggestion": "‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ"}]
  },
  "visual_suggestions": [{"time": 20, "suggestion": "zoom in", "priority": "high"}],
  "audio_suggestions": [{"start": 0, "end": 10, "type": "music", "intensity": "medium"}]
}

‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:
1. Structure: ‡πÅ‡∏ö‡πà‡∏á intro/main/outro
2. Pacing: ‡∏´‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î‡∏ä‡πâ‡∏≤/‡πÄ‡∏£‡πá‡∏ß ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏£‡∏ï‡∏±‡∏î
3. Engagement: ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô hook, ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏ô‡∏î‡∏£‡∏≠‡∏õ
4. Visual: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ zoom, text overlay
5. Audio: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏î‡∏ô‡∏ï‡∏£‡∏µ, sfx`

            const completion = await groq.chat.completions.create({
                model: 'llama-3.3-70b-versatile',
                messages: [{ role: 'user', content: prompt }],
                temperature: 0.7,
                max_tokens: 2000
            })

            const response = completion.choices[0]?.message?.content
            if (!response) return null

            const match = response.match(/\{[\s\S]*\}/)
            if (!match) return null

            const parsed = JSON.parse(match[0])

            console.log(`‚úÖ Deep analysis: hook ${parsed.engagement?.hook_quality}/100`)

            return parsed
        } catch (error) {
            console.error('Deep analysis failed:', error)
            return null
        }
    }

    private mockTranscription(): TranscriptionResult {
        return {
            text: "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å AI services ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô",
            segments: [
                { start: 0, end: 3, text: "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á" },
                { start: 3, end: 6, text: "‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö" },
                { start: 6, end: 10, text: "AI ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô" },
            ]
        }
    }

    private mockKeywords(): KeywordResult {
        return {
            topics: ["‡∏ó‡∏î‡∏™‡∏≠‡∏ö", "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"],
            viral_keywords: [],
            seo_keywords: [],
            highlight_words: [],
            suggested_hashtags: ["#test"],
            content_category: "general",
            target_audience: "general",
            emotion_tone: "neutral"
        }
    }

    private async transcribeWithGroq(videoBlob: Blob): Promise<TranscriptionResult> {
        const Groq = require('groq-sdk').default
        const groq = new Groq({ apiKey: this.groqKey })

        const sizeMB = videoBlob.size / (1024 * 1024)
        if (sizeMB > 25) {
            throw new Error(`Video too large: ${sizeMB.toFixed(2)}MB (max 25MB)`)
        }

        const file = new File([videoBlob], 'video.mp4', { type: 'video/mp4' })

        // Common Thai words to help Whisper recognize correctly
        const thaiPrompt = `‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢: ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏°‡∏±‡∏á‡∏Ñ‡∏∏‡∏î ‡∏•‡∏≥‡πÑ‡∏¢ ‡∏•‡∏¥‡πâ‡∏ô‡∏à‡∏µ‡πà ‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ ‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà ‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì`

        const transcription = await groq.audio.transcriptions.create({
            file: file,
            model: 'whisper-large-v3',
            language: 'th',
            response_format: 'verbose_json',
            timestamp_granularities: ['word', 'segment'],
            temperature: 0.0,
            prompt: thaiPrompt,  // ‡πÄ‡∏û‡∏¥‡πà‡∏° prompt hint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
        })

        if (!transcription.text) {
            throw new Error('Empty transcription')
        }

        const result: TranscriptionResult = {
            text: transcription.text,
            segments: (transcription.segments || []).map((seg: any) => ({
                start: seg.start || 0,
                end: seg.end || 0,
                text: seg.text || ''
            }))
        }

        console.log(`‚úÖ Groq transcribed: ${result.segments.length} segments, ${transcription.words?.length || 0} words`)
        return result
    }

    private async transcribeWithGemini(videoBlob: Blob): Promise<TranscriptionResult> {
        const { GoogleGenAI } = require('@google/genai')
        const ai = new GoogleGenAI({ apiKey: this.geminiKey })

        const arrayBuffer = await videoBlob.arrayBuffer()
        const base64Video = Buffer.from(arrayBuffer).toString('base64')

        const sizeMB = videoBlob.size / (1024 * 1024)
        if (sizeMB > 50) {
            throw new Error(`Video too large: ${sizeMB.toFixed(2)}MB (max 50MB)`)
        }

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: [{
                role: 'user',
                parts: [
                    { text: `‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô JSON:\n{"text": "...", "segments": [{"start": 0, "end": 2, "text": "..."}]}` },
                    { inlineData: { mimeType: 'video/mp4', data: base64Video } }
                ]
            }]
        })

        const text = response.text
        if (!text) throw new Error('Empty response')

        const match = text.match(/\{[\s\S]*\}/)
        if (!match) throw new Error('No JSON')

        const clean = match[0].replace(/[\u0000-\u001F\u007F-\u009F]/g, '')
        const parsed = JSON.parse(clean)

        if (!parsed.text || !Array.isArray(parsed.segments)) {
            throw new Error('Invalid structure')
        }

        console.log(`‚úÖ Gemini transcribed: ${parsed.segments.length} segments`)
        return parsed
    }

    // Enhanced analysis (backward compatible)
    async analyzeTranscript(transcript: TranscriptionResult): Promise<AnalysisResult | null> {
        if (transcript.text.includes("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á")) {
            return {
                summary: "Mock analysis",
                highlights: [],
                jumpCuts: [],
                keywords: []
            }
        }

        if (!this.groqKey) return null

        try {
            const Groq = require('groq-sdk').default
            const groq = new Groq({ apiKey: this.groqKey })

            const response = await groq.chat.completions.create({
                model: 'llama-3.3-70b-versatile',
                messages: [{
                    role: 'user',
                    content: `‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: ${transcript.text}\n\nJSON: {"summary":"...","highlights":[],"jumpCuts":[],"keywords":[]}`
                }],
                temperature: 0.7,
                max_tokens: 2000
            })

            const text = response.choices[0]?.message?.content
            const match = text?.match(/\{[\s\S]*\}/)
            return match ? JSON.parse(match[0]) : null
        } catch (error) {
            console.error('Analysis failed:', error)
            return null
        }
    }
}
